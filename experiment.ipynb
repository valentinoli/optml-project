{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixture model experiment\n",
    "In this notebook we perform the experiment to verify that we indeed see an exponential amount of gradient queries for stochastic gradient descent with an increasing parameter $d$, whereas we observe a linear relation in the case of the Metropolis-adjusted Langevin algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the data\n",
    "We begin by generating the datasets used in our evaluation. Since we are trying various distributions, we have to make sure that they are all parameterized properly so as to achieve the following properties:\n",
    "1. The clusters need to be adequately separated.\n",
    "2. The amount of clusters in our dataset needs to be few ($M=\\log_2 d$ in paper).\n",
    "\n",
    "Something we could consider trying out would be to violate these properties to see what the failure mode is.\n",
    "\n",
    "In our experiment we use the following distributions (we always let $N=2^d$):\n",
    "1. Gaussian $\\sigma = 1 / \\sqrt{d}, M=\\log_2 d$\n",
    "2. Dirichlet\n",
    "3. Exponential\n",
    "4. Student's T (included since not log-concave for all parameters)\n",
    "\n",
    "For our experiment to work, we need to generate new such problems for an increasing parameter $d$. Therefore we will need in total $4d$ datasets to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "Now we begin the experiment. The setup is quite simplistic:\n",
    "1. Iterate over parameter $d$.\n",
    "2. Gather our distribution datasets for that parameter $d$.\n",
    "3. Estimate the parameters of the distribution using expectation-maximization.\n",
    "4. Estimate the parameters of the distribution using MALA.\n",
    "5. Save the amount of gradient queries required for both approaches.\n",
    "6. Create line plot of required gradient queries for convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [i for i in range(1, 10)]\n",
    "iterations = len(ds)\n",
    "\n",
    "gauss_gq_EM = np.zeros(len(ds))\n",
    "gauss_gq_MALA = np.zeros(len(ds))\n",
    "dirichlet_gq_EM = np.zeros(len(ds))\n",
    "dirichlet_gq_MALA = np.zeros(len(ds))\n",
    "exponential_gq_EM = np.zeros(len(ds))\n",
    "exponential_gq_MALA = np.zeros(len(ds))\n",
    "students_gq_EM = np.zeros(len(ds))\n",
    "students_gq_MALA = np.zeros(len(ds))\n",
    "\n",
    "# Iterate and gather datasets\n",
    "for i, d in tqdm(enumerate(ds)):\n",
    "    \n",
    "    # Compute necessary parameters\n",
    "    components = int(math.log(d, 2))\n",
    "    \n",
    "    # Load correct dataset\n",
    "    g = gaussian[d]\n",
    "    d = dirichlet[d]\n",
    "    e = exponential[d]\n",
    "    s = students[d]\n",
    "    \n",
    "    # Run EM\n",
    "    gauss_gq_EM[i] = EM_until_convergence(g, k=components)\n",
    "    dirichlet_gq_EM[i] = EM_until_convergence(d, k=components)\n",
    "    exponential_gq_EM[i] = EM_until_convergence(e, k=components)\n",
    "    students_gq_EM[i] = EM_until_convergence(s, k=components)\n",
    "\n",
    "    # Run MALA\n",
    "    gauss_gq_MALA[i] = MALA_until_convergence(g, k=components)\n",
    "    dirichlet_gq_MALA[i] = MALA_until_convergence(d, k=components)\n",
    "    exponential_gq_MALA[i] = MALA_until_convergence(e, k=components)\n",
    "    students_gq_MALA[i] = MALA_until_convergence(s, k=components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "Now that we have all the necessary data we can examine our results to see if they make sense in the context of the paper we are referencing.\n",
    "\n",
    "We begin by generating figures for the individual mixture problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian\n",
    "gdf = pd.DataFrame({'Dimensions': ds + ds, \n",
    "                    'Gradient queries': np.concatenate((gauss_gq_EM, gauss_gq_MALA)), \n",
    "                    'Algorithm': ['EM']*iterations + ['MALA']*iterations})\n",
    "sns.lineplot(data=gdf, x='Dimensions', y='Gradient queries', hue='Algorithm').set_title('Gaussian Mixture Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirichlet\n",
    "ddf = pd.DataFrame({'Dimensions': ds + ds, \n",
    "                    'Gradient queries': np.concatenate((dirichlet_gq_EM, dirichlet_gq_MALA)), \n",
    "                    'Algorithm': ['EM']*iterations + ['MALA']*iterations})\n",
    "sns.lineplot(data=ddf, x='Dimensions', y='Gradient queries', hue='Algorithm').set_title('Dirichlet Mixture Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential\n",
    "edf = pd.DataFrame({'Dimensions': ds + ds, \n",
    "                    'Gradient queries': np.concatenate((exponential_gq_EM, exponential_gq_MALA)), \n",
    "                    'Algorithm': ['EM']*iterations + ['MALA']*iterations})\n",
    "sns.lineplot(data=edf, x='Dimensions', y='Gradient queries', hue='Algorithm').set_title('Exponential Mixture Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student's T\n",
    "tdf = pd.DataFrame({'Dimensions': ds + ds, \n",
    "                    'Gradient queries': np.concatenate((students_gq_EM, students_gq_MALA)), \n",
    "                    'Algorithm': ['EM']*iterations + ['MALA']*iterations})\n",
    "sns.lineplot(data=tdf, x='Dimensions', y='Gradient queries', hue='Algorithm').set_title('Student\\'s T Mixture Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLABLABLA analysis BLABLABLA\n",
    "\n",
    "Let us now also generate a large figure containing the data for all datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = pd.DataFrame({'Dimensions': ds*8, \n",
    "                    'Gradient queries': np.concatenate((gaussian_gq_EM, gaussian_gq_MALA,\n",
    "                                                        dirichlet_gq_EM, dirichlet_gq_MALA,\n",
    "                                                        exponential_gq_EM, exponential_gq_MALA, \n",
    "                                                        students_gq_EM, students_gq_MALA)), \n",
    "                    'Combination': ['Gaussian (EM)']*iterations + ['Gaussian (MALA)']*iterations +\n",
    "                                   ['Dirichlet (EM)']*iterations + ['Dirichlet (MALA)']*iterations +\n",
    "                                   ['Exponential (EM)']*iterations + ['Exponential (MALA)']*iterations +\n",
    "                                   ['Student\\'s T (EM)']*iterations + ['Student\\'s T (MALA)']*iterations +})\n",
    "sns.lineplot(data=adf, x='Dimensions', y='Gradient queries', hue='Combination').set_title('All Mixture Models')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaexam",
   "language": "python",
   "name": "adaexam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixture model experiment\n",
    "In this notebook we perform the experiment to verify that we indeed see an exponential amount of gradient queries for stochastic gradient descent with an increasing parameter $d$, whereas we observe a linear relation in the case of the Metropolis-adjusted Langevin algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from matplotlib.patches import Circle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the data\n",
    "We begin by generating the datasets used in our evaluation. Since we are trying various distributions, we have to make sure that they are all parameterized properly so as to achieve the following properties:\n",
    "1. The clusters need to be adequately separated.\n",
    "2. The amount of clusters in our dataset needs to be few ($M=\\log_2 d$ in paper).\n",
    "\n",
    "Something we could consider trying out would be to violate these properties to see what the failure mode is.\n",
    "\n",
    "In our experiment we use the following distributions (we always let $N=2^d$):\n",
    "1. Gaussian $\\sigma = 1 / \\sqrt{d}, M=\\log_2 d$\n",
    "2. Dirichlet\n",
    "3. Exponential\n",
    "4. Student's T (included since not log-concave for all parameters)\n",
    "\n",
    "For our experiment to work, we need to generate new such problems for an increasing parameter $d$. Therefore we will need in total $4d$ datasets to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "Now we begin the experiment. The setup is quite simplistic:\n",
    "1. Iterate over parameter $d$.\n",
    "2. Gather our distribution datasets for that parameter $d$.\n",
    "3. Estimate the parameters of the distribution using expectation-maximization.\n",
    "4. Estimate the parameters of the distribution using MALA.\n",
    "5. Save the amount of gradient queries required for both approaches.\n",
    "6. Create line plot of required gradient queries for convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/54544972/8238129\n",
    "# Generate \"num_points\" random points in \"dimension\" that have uniform\n",
    "# probability over the unit ball scaled by \"radius\" (length of points\n",
    "# are in range [0, \"radius\"]).\n",
    "def random_ball(num_points: int, dimension: int, radius: int = 1):\n",
    "    # First generate random directions by normalizing the length of a\n",
    "    # vector of random-normal values (these distribute evenly on ball).\n",
    "    random_directions = np.random.normal(size=(dimension, num_points))\n",
    "    random_directions /= np.linalg.norm(random_directions, axis=0)\n",
    "    # Second generate a random radius with probability proportional to\n",
    "    # the surface area of a ball with a given radius.\n",
    "    random_radii = np.random.random(num_points) ** (1 / dimension)\n",
    "    # Return the list of random (direction & length) points.\n",
    "    return radius * (random_directions * random_radii).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_points_in_ball(num_points: int = 1000, radius: int = 1, dim: int = 2):\n",
    "    if dim < 2 or dim > 3:\n",
    "        raise ValueError('Invalid dimension')\n",
    "\n",
    "    points = random_ball(num_points, dim, radius=radius)\n",
    "\n",
    "    subplot_kw = {}\n",
    "\n",
    "    if dim == 3:\n",
    "        subplot_kw=dict(projection='3d')\n",
    "        sns.set(style = \"darkgrid\")\n",
    "\n",
    "    fig, ax = plt.subplots(subplot_kw=subplot_kw)\n",
    "\n",
    "    if dim == 2:\n",
    "        ax.set_aspect('equal')\n",
    "        patch = Circle((0, 0), radius, fill=False, ls='-', lw=0.25)\n",
    "        ax.add_patch(patch)\n",
    "\n",
    "    ax.scatter(*np.split(points, dim, axis=1), marker='.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot_points_in_ball(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mixture():\n",
    "    def __init__(self, d: int):\n",
    "        # dimension\n",
    "        self.d = d\n",
    "        # number of mixtures\n",
    "        self.M = int(math.log(d, 2))\n",
    "        \n",
    "    def pdf(self, x: np.ndarray):\n",
    "        raise NotImplementedError\n",
    "\n",
    "        \n",
    "class GaussianMixture(Mixture):\n",
    "    \"\"\"Class for the Gaussian Mixture Model experiment\"\"\"\n",
    "    def __init__(self, d: int, init_from_data: bool = True):\n",
    "        super().__init__(d)\n",
    "        # radius containing the data\n",
    "        self.R = 2 * self.M\n",
    "    \n",
    "        # variance\n",
    "        self.var = 1 / d\n",
    "        \n",
    "        # covariance matrix (isotropic and uniform)\n",
    "        # self.cov = np.diag(np.repeat(self.var, d))\n",
    "        \n",
    "        # normalization constant for each Gaussian is the same\n",
    "        # self.Z = math.sqrt(((2 * math.pi) ** d) * np.linalg.det(self.cov))\n",
    "        self.Z = math.sqrt(((2 * math.pi * self.var) ** d))\n",
    "        # lambda_i's\n",
    "        self.lambda_ = self.Z * self.var / 1000\n",
    "\n",
    "        self.points = self.sample()\n",
    "        self.mu = self.init_params(init_from_data)\n",
    "\n",
    "\n",
    "    def sample(self) -> np.ndarray:\n",
    "        \"\"\"Create synthetic dataset with sparse entries for GMM experiment\"\"\"\n",
    "        rng = np.random.default_rng()\n",
    "        d = self.d\n",
    "        # number of data points\n",
    "        N = 2 ** d\n",
    "\n",
    "        # number of nonzero entries of each point\n",
    "        num_nonzero = self.M\n",
    "\n",
    "        # create ndarray of permuted indices of each data point\n",
    "        idx = np.array([\n",
    "            rng.permutation(i) for i in np.tile(np.arange(d), (N, 1))\n",
    "        ])\n",
    "\n",
    "        # M nonzero entries, selected uniformly at random\n",
    "        idx_nonzero = idx[:, :num_nonzero]\n",
    "\n",
    "        # initialize points array with zeros\n",
    "        points = np.zeros(idx.shape)\n",
    "\n",
    "        # all nonzero entries follow a uniform distribution on [-1, 1]\n",
    "        for i, indices in enumerate(idx_nonzero):\n",
    "            points[i, indices] = rng.uniform(low=-1, high=1, size=num_nonzero)\n",
    "        return points\n",
    "\n",
    "\n",
    "    def init_params(self, from_data: bool) -> np.ndarray:\n",
    "        if from_data:\n",
    "            # initialize cluster centers from data\n",
    "            rng = np.random.default_rng()\n",
    "            return rng.choice(self.points, size=self.M)\n",
    "        \n",
    "        # initialize in ball of radius R\n",
    "        return random_ball(num_points=self.M, radius=self.R, dim=self.d)\n",
    "\n",
    "        \n",
    "    def pdf_constant_mixture(self):\n",
    "        # Computes the constant mixture\n",
    "        # Assume data are distributed in a bounded region\n",
    "        # and take this constant mixture to describe that observation\n",
    "        # Z_0 == Z ?\n",
    "        return (np.linalg.norm(self.points, axis=1) <= self.R).astype(int) / self.Z\n",
    "        \n",
    "    def pdf(self) -> float:\n",
    "        norm_diff = np.linalg.norm(self.points[:, None, :] - self.mu[None, :, :], axis=2)\n",
    "        exponent = -0.5 * norm_diff ** 2 / self.var\n",
    "        const_mix = (1 - self.M * self.lambda_) * self.pdf_constant_mixture()\n",
    "        return (self.var / 1000) * np.exp(exponent).sum() + const_mix\n",
    "        \n",
    "    def prior(self):\n",
    "        # Computes the prior term        \n",
    "        sqrt_M_times_R = math.sqrt(M) * self.R\n",
    "        # Frobenius norm of means matrix\n",
    "        fro = np.linalg.norm(self.mu)\n",
    "        return np.exp(-M * (fro - sqrt_M_times_R) ** 2 * int(fro >= sqrt_M_times_R))\n",
    "         \n",
    "        \n",
    "    def objective(self):\n",
    "        return -np.log(self.prior()) - np.sum(np.log(self.pdf()))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = GaussianMixture(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.objective()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def em(model):\n",
    "    \"\"\"Expectation Maximization Algorithm\"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "def mala():\n",
    "    \"\"\"Metropolis-adjusted Langevin algorithm\"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = range(2, 10)\n",
    "\n",
    "models = [\n",
    "    GaussianMixture\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame(\n",
    "    np.nan,\n",
    "    index=dims,\n",
    "    columns=pd.MultiIndex.from_product((models, ['em', 'mala']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate and gather datasets\n",
    "for d in tqdm(dims):\n",
    "    # components = int(math.log(d, 2))\n",
    "    \n",
    "    for constructor in models:\n",
    "        model = constructor(d)\n",
    "        \n",
    "        # Run EM\n",
    "        results_df.loc[d, (m, 'em')] = em(data, k=components)\n",
    "        \n",
    "        # Run MALA\n",
    "        results_df.loc[d, (m, 'mala')] = mala(data, k=components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "Now that we have all the necessary data we can examine our results to see if they make sense in the context of the paper we are referencing.\n",
    "\n",
    "We begin by generating figures for the individual mixture problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    results_model = results_df[m]\n",
    "    \n",
    "    print(results_df[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian\n",
    "gdf = pd.DataFrame({'Dimensions': ds + ds, \n",
    "                    'Gradient queries': np.concatenate((gauss_gq_EM, gauss_gq_MALA)), \n",
    "                    'Algorithm': ['EM']*iterations + ['MALA']*iterations})\n",
    "sns.lineplot(data=gdf, x='Dimensions', y='Gradient queries', hue='Algorithm').set_title('Gaussian Mixture Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirichlet\n",
    "ddf = pd.DataFrame({'Dimensions': ds + ds, \n",
    "                    'Gradient queries': np.concatenate((dirichlet_gq_EM, dirichlet_gq_MALA)), \n",
    "                    'Algorithm': ['EM']*iterations + ['MALA']*iterations})\n",
    "sns.lineplot(data=ddf, x='Dimensions', y='Gradient queries', hue='Algorithm').set_title('Dirichlet Mixture Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential\n",
    "edf = pd.DataFrame({'Dimensions': ds + ds, \n",
    "                    'Gradient queries': np.concatenate((exponential_gq_EM, exponential_gq_MALA)), \n",
    "                    'Algorithm': ['EM']*iterations + ['MALA']*iterations})\n",
    "sns.lineplot(data=edf, x='Dimensions', y='Gradient queries', hue='Algorithm').set_title('Exponential Mixture Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student's T\n",
    "tdf = pd.DataFrame({'Dimensions': ds + ds, \n",
    "                    'Gradient queries': np.concatenate((students_gq_EM, students_gq_MALA)), \n",
    "                    'Algorithm': ['EM']*iterations + ['MALA']*iterations})\n",
    "sns.lineplot(data=tdf, x='Dimensions', y='Gradient queries', hue='Algorithm').set_title('Student\\'s T Mixture Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLABLABLA analysis BLABLABLA\n",
    "\n",
    "Let us now also generate a large figure containing the data for all datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = pd.DataFrame({'Dimensions': ds*8, \n",
    "                    'Gradient queries': np.concatenate((gaussian_gq_EM, gaussian_gq_MALA,\n",
    "                                                        dirichlet_gq_EM, dirichlet_gq_MALA,\n",
    "                                                        exponential_gq_EM, exponential_gq_MALA, \n",
    "                                                        students_gq_EM, students_gq_MALA)), \n",
    "                    'Combination': ['Gaussian (EM)']*iterations + ['Gaussian (MALA)']*iterations +\n",
    "                                   ['Dirichlet (EM)']*iterations + ['Dirichlet (MALA)']*iterations +\n",
    "                                   ['Exponential (EM)']*iterations + ['Exponential (MALA)']*iterations +\n",
    "                                   ['Student\\'s T (EM)']*iterations + ['Student\\'s T (MALA)']*iterations +})\n",
    "sns.lineplot(data=adf, x='Dimensions', y='Gradient queries', hue='Combination').set_title('All Mixture Models')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
